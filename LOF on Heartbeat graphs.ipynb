{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Outlier Detection on Heartbeat graphs\n",
    "\n",
    "I am using Local Outlier Factor (LOF) method and k-nearest neighbors to do anomaly detection on the graph representation of the heart beat signal.\n",
    "\n",
    "This notebook, is completing the final step of our pipeline and combining the steps and results of <code>MIT-BIH-Kaggle</code> notebook with <code>KNN_AnomalyDetection_OnGraphs</code> to have a complete process from a raw signal to detect anomalies for each heartbeat of the signal using its coresponding graph.\n",
    "\n",
    "The outlies are the followings:\n",
    "1. Create graph stream from the original signal.\n",
    "2. Compute the pairwise distance between each two graphs and produce the distance matrix using Graph edit distance.\n",
    "3. Feed the distance matrix for our graph stream into a Local Outlier Factor (LOF) model and detect the abnormal graphs (Each graph corespond to a heartbeat).\n",
    "4. Compare the detected graph with the ground truth, The actual label of the heartbeat is labeled by expert Cardialogists, and compute the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph stream from the original signal.\n",
    "Lets generate our graph stream from the **MIT-BIH** dataset using the helper functions which implemented  in <code>MIT-BIH-Kaggle</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from myHelper import timing\n",
    "from myHelper import GraphSignalHelper\n",
    "\n",
    "data_df = GraphSignalHelper.read_heartbeat_database(name='100', nRowsRead=3000)\n",
    "annotations_df = GraphSignalHelper.read_annotation_database(name='100')\n",
    "\n",
    "graph_stream, graph_stream_labels = GraphSignalHelper.generate_graph_stream(data_df, annotations_df, fs = 360)\n",
    "\n",
    "# len(graph_stream) = 2272\n",
    "\n",
    "# graph_stream_labels[1]['Type']\n",
    "# 2    N\n",
    "# 3    N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate gragh edit distance matrix\n",
    "Compute the pairwise distance between each two graphs and produce the distance matrix using Graph edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GED_distance_matrix took 99325.33574104309   mil sec\n",
      "precomputed distance matrix =\n",
      " [[   0.   552.  1036.  1021.  1038.   647.5 1612.5 1907.5 1040.5]\n",
      " [ 552.     0.  1011.  1003.  1011.   644.5 1584.  1920.  1012.5]\n",
      " [1036.  1011.     0.   540.   536.   987.  1518.5 2086.  1133.5]\n",
      " [1021.  1003.   540.     0.   528.   992.5 1352.  2062.5 1145.5]\n",
      " [1038.  1011.   536.   528.     0.   979.  1423.  2091.  1127.5]\n",
      " [ 647.5  644.5  987.   992.5  979.     0.  1602.  1914.5 1011. ]\n",
      " [1612.5 1584.  1518.5 1352.  1423.  1602.     0.  2684.  1725.5]\n",
      " [1907.5 1920.  2086.  2062.5 2091.  1914.5 2684.     0.  1838. ]\n",
      " [1040.5 1012.5 1133.5 1145.5 1127.5 1011.  1725.5 1838.     0. ]]\n"
     ]
    }
   ],
   "source": [
    "from myHelper import timing\n",
    "\n",
    "# Gmatch4py use networkx graph \n",
    "import networkx as nx \n",
    "# import the GED using the munkres algorithm\n",
    "import gmatch4py as gm\n",
    "\n",
    "\n",
    "@timing.time_it\n",
    "def GED_distance_matrix(graph_series):\n",
    "    # convert from dictionary of graphs to list of graphs\n",
    "    graph_stream_list = [v for k, v in graph_stream.items()] \n",
    "    ged=gm.GraphEditDistance(1,1,1,1) # all edit costs are equal to 1\n",
    "    non_symetric_GED_matrix=ged.compare(graph_stream_list,None)\n",
    "    symetric_ged_matrix = (non_symetric_GED_matrix.transpose()+non_symetric_GED_matrix)/2\n",
    "    return symetric_ged_matrix\n",
    "\n",
    "distance_matrix = GED_distance_matrix(graph_stream)\n",
    "print(\"precomputed distance matrix =\\n\",distance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly detection on graphs using distance matrix\n",
    "Feed the distance matrix for our graph stream into a Local Outlier Factor (LOF) model and detect the abnormal graphs (Each graph corespond to a heartbeat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier prediction (-1 = abnormal, 1 = normal) \n",
      "\n",
      " [ 1  1  1  1  1  1 -1 -1 -1]\n",
      "\n",
      " Outlier threshold =  1.5\n",
      "\n",
      " Outlier scores (1 = normal, 1 >> abnormal)= \n",
      " \n",
      " [0.9988417  1.00232198 0.99814815 0.99814815 1.00371747 0.9988417\n",
      " 2.57422036 2.37499727 1.56436237]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=2,\n",
    "                         algorithm=\"brute\",\n",
    "                         metric=\"precomputed\",\n",
    "#                          contamination=0.01, # the proportion of outliers in the data set float \n",
    "                         contamination='auto', # the proportion of outliers in the data set float \n",
    "                         novelty=False, # novelty=True if you want to use LOF for novelty \n",
    "                                        # detection and predict on new unseen data\n",
    "                         n_jobs=None)\n",
    "\n",
    "clf.fit(X=distance_matrix)\n",
    "\n",
    "\n",
    "# predict on training data\n",
    "# Fits the model to the training set X and returns the labels.\n",
    "outlier_prediction = clf.fit_predict(X=distance_matrix)\n",
    "print(\"outlier prediction (-1 = abnormal, 1 = normal) \\n\\n\",\n",
    "      outlier_prediction)\n",
    "\n",
    "# Fit the model using X as training data.\n",
    "clf.fit(X=distance_matrix)\n",
    "\n",
    "# Observations having a negative_outlier_factor smaller than offset_ are detected as abnormal.\n",
    "# The offset is set to -1.5 (inliers score around -1), except when\n",
    "# a contamination parameter different than “auto” is provided.\n",
    "print(\"\\n Outlier threshold = \", -(clf.offset_))\n",
    "\n",
    "\n",
    "# Only available for novelty detection (when novelty is set to True).\n",
    "# The shift offset allows a zero threshold for being an outlier.\n",
    "# print(\"decision_function = \", clf.decision_function(X=symetric_result))\n",
    "\n",
    "\n",
    "#  negative_outlier_factor_ndarray shape (n_samples,)\n",
    "#  negative_outlier_factor_ = -1 normal\n",
    "#  negative_outlier_factor_ << -1 abnormal \n",
    "print(\"\\n Outlier scores (1 = normal, 1 >> abnormal)= \\n \\n\", -(clf.negative_outlier_factor_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation to the real labels\n",
    "Compare the detected anomaly graphs with the ground truth, The actual label of the heartbeat is labeled by expert Cardialogists, and compute the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For graph  0   =  ['Normal']\n",
      "For graph  1   =  ['Normal' 'Normal']\n",
      "For graph  2   =  ['Normal']\n",
      "For graph  3   =  []\n",
      "For graph  4   =  ['Normal']\n",
      "For graph  5   =  ['Normal']\n",
      "For graph  6   =  ['Normal' 'Abnormal']\n",
      "For graph  7   =  ['Normal']\n",
      "For graph  8   =  []\n"
     ]
    }
   ],
   "source": [
    "for graph_index, graph_annotation in enumerate(graph_stream_labels):\n",
    "    Label = np.where(graph_annotation[\"Type\"] == \"N\", \"Normal\", \"Abnormal\")\n",
    "    print(\"For graph \", graph_index, \"  = \", Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first 9 heartbeats it works and the result is acceptable. However, the problem is still the running time of the model.\n",
    "\n",
    "If I run the code for all the rows of the dataset it will give me 2272 heartbeat. For this 2272 graphs, I have to compute the distance matrix of size $(2272*2272)$ which does not exceed my memory capacity but it will take 73 days to compute this distance matrix using <code>gmatch4py</code> algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
